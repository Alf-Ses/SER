name: crema-d
description: 'CREMA-D: Crowd-sourced Emotional Mutimodal Actors Dataset CREMA-D is
  a data set of 7,442 original clips from 91 actors.  These clips were from 48 male
  and 43 female actors between the ages of 20 and 74  coming from a variety of races
  and ethnicities  (African America, Asian, Caucasian, Hispanic, and Unspecified).
  When using the database commercially, the database must be referenced together with
  its license.'
source: https://github.com/CheyneyComputerScience/CREMA-D
usage: commercial
languages: [English]
author: Houwei Cao, David G. Cooper, Michael K. Keutmann, Ruben C. Gur, Ani Nenkova,
  Ragini Verma, Samantha L Moore, Adam Savitt
license: Open Data Commons Open Database License (ODbL) v1.0
license_url: http://opendatacommons.org/licenses/odbl/1.0/
media:
  microphone: {type: audio, format: wav, channels: 1, sampling_rate: 16000}
schemes:
  corrupted: {description: Whether the audio file is corrupted, dtype: bool}
  emotion:
    dtype: str
    labels: [anger, disgust, fear, happiness, neutral, no_agreement, sadness]
  emotion.agreement: {dtype: float, minimum: 0, maximum: 1}
  emotion.intensity:
    dtype: str
    labels: [low, mid, high, unspecified]
  emotion.level: {description: Level of emotional expression. A high value corresponds
      to a strong emotional expression for the associated emotion label., dtype: float,
    minimum: 0, maximum: 100}
  sentence:
    dtype: str
    labels: {IEO: It's eleven o'clock, TIE: That is exactly what happened, IOM: I'm
        on my way to the meeting, IWW: I wonder what this is about, TAI: The airplane
        is almost full, MTI: Maybe tomorrow it will be cold, IWL: I would like a new
        alarm clock, ITH: I think I have a doctor's appointment, DFA: Don't forget
        a jacket, ITS: I think I've seen this before, TSI: The surface is slick, WSI: We'll
        stop in a couple of minutes}
  speaker:
    dtype: int
    labels:
      1001: {age: 51, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1002: {age: 21, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1003: {age: 21, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1004: {age: 42, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1005: {age: 29, sex: male, race: African American, ethnicity: Not Hispanic}
      1006: {age: 58, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1007: {age: 38, sex: female, race: African American, ethnicity: Not Hispanic}
      1008: {age: 46, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1009: {age: 24, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1010: {age: 27, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1011: {age: 32, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1012: {age: 23, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1013: {age: 22, sex: female, race: Caucasian, ethnicity: Hispanic}
      1014: {age: 24, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1015: {age: 32, sex: male, race: African American, ethnicity: Not Hispanic}
      1016: {age: 61, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1017: {age: 42, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1018: {age: 25, sex: female, race: Caucasian, ethnicity: Hispanic}
      1019: {age: 29, sex: male, race: Asian, ethnicity: Not Hispanic}
      1020: {age: 61, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1021: {age: 30, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1022: {age: 22, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1023: {age: 22, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1024: {age: 59, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1025: {age: 48, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1026: {age: 33, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1027: {age: 44, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1028: {age: 57, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1029: {age: 33, sex: female, race: African American, ethnicity: Not Hispanic}
      1030: {age: 42, sex: female, race: African American, ethnicity: Not Hispanic}
      1031: {age: 31, sex: male, race: Caucasian, ethnicity: Hispanic}
      1032: {age: 30, sex: male, race: African American, ethnicity: Not Hispanic}
      1033: {age: 31, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1034: {age: 74, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1035: {age: 48, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1036: {age: 49, sex: male, race: African American, ethnicity: Not Hispanic}
      1037: {age: 45, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1038: {age: 21, sex: male, race: African American, ethnicity: Not Hispanic}
      1039: {age: 51, sex: male, race: African American, ethnicity: Not Hispanic}
      1040: {age: 42, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1041: {age: 42, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1042: {age: 37, sex: male, race: African American, ethnicity: Not Hispanic}
      1043: {age: 25, sex: female, race: Caucasian, ethnicity: Hispanic}
      1044: {age: 40, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1045: {age: 22, sex: male, race: Asian, ethnicity: Not Hispanic}
      1046: {age: 22, sex: female, race: Caucasian, ethnicity: Hispanic}
      1047: {age: 22, sex: female, race: Unknown, ethnicity: Hispanic}
      1048: {age: 38, sex: male, race: Caucasian, ethnicity: Hispanic}
      1049: {age: 25, sex: female, race: Caucasian, ethnicity: Hispanic}
      1050: {age: 62, sex: male, race: African American, ethnicity: Not Hispanic}
      1051: {age: 56, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1052: {age: 33, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1053: {age: 35, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1054: {age: 36, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1055: {age: 57, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1056: {age: 52, sex: female, race: African American, ethnicity: Not Hispanic}
      1057: {age: 25, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1058: {age: 36, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1059: {age: 21, sex: male, race: African American, ethnicity: Not Hispanic}
      1060: {age: 28, sex: female, race: African American, ethnicity: Not Hispanic}
      1061: {age: 51, sex: female, race: African American, ethnicity: Not Hispanic}
      1062: {age: 56, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1063: {age: 33, sex: female, race: African American, ethnicity: Not Hispanic}
      1064: {age: 53, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1065: {age: 38, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1066: {age: 25, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1067: {age: 66, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1068: {age: 34, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1069: {age: 27, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1070: {age: 25, sex: male, race: African American, ethnicity: Not Hispanic}
      1071: {age: 41, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1072: {age: 33, sex: female, race: Asian, ethnicity: Not Hispanic}
      1073: {age: 24, sex: female, race: African American, ethnicity: Hispanic}
      1074: {age: 31, sex: female, race: African American, ethnicity: Not Hispanic}
      1075: {age: 40, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1076: {age: 25, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1077: {age: 20, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1078: {age: 21, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1079: {age: 21, sex: female, race: Caucasian, ethnicity: Hispanic}
      1080: {age: 21, sex: male, race: African American, ethnicity: Not Hispanic}
      1081: {age: 30, sex: male, race: Asian, ethnicity: Not Hispanic}
      1082: {age: 20, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1083: {age: 45, sex: male, race: African American, ethnicity: Not Hispanic}
      1084: {age: 46, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1085: {age: 34, sex: male, race: Asian, ethnicity: Not Hispanic}
      1086: {age: 33, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1087: {age: 62, sex: male, race: Caucasian, ethnicity: Not Hispanic}
      1088: {age: 23, sex: male, race: African American, ethnicity: Not Hispanic}
      1089: {age: 24, sex: female, race: Caucasian, ethnicity: Not Hispanic}
      1090: {age: 50, sex: male, race: Asian, ethnicity: Not Hispanic}
      1091: {age: 29, sex: female, race: Asian, ethnicity: Not Hispanic}
  votes: {description: Number of times a rater voted for a label, dtype: int, minimum: 0}
splits:
  dev: {description: Unofficial speaker-independent dev split, type: dev}
  test: {description: Unofficial speaker-independent test split, type: test}
  train: {description: Unofficial speaker-independent train split, type: train}
tables:
  age.dev:
    type: filewise
    description: Table selected for age and binary gender balance from the emotionally
      neutral samples,  limited to 20 samples per speaker.
    columns:
      speaker: {scheme_id: speaker}
  age.emotional.dev:
    type: filewise
    description: Table selected for age and binary gender balance from all samples,
      limited to 20 samples per speaker.
    columns:
      speaker: {scheme_id: speaker}
  age.emotional.test:
    type: filewise
    description: Table selected for age and binary gender balance from all samples,
      limited to 20 samples per speaker.
    columns:
      speaker: {scheme_id: speaker}
  age.emotional.train:
    type: filewise
    description: Table selected for age and binary gender balance from all samples,
      limited to 20 samples per speaker.
    columns:
      speaker: {scheme_id: speaker}
  age.test:
    type: filewise
    description: Table selected for age and binary gender balance from the emotionally
      neutral samples,  limited to 20 samples per speaker.
    columns:
      speaker: {scheme_id: speaker}
  age.train:
    type: filewise
    description: Table selected for age and binary gender balance from the emotionally
      neutral samples,  limited to 20 samples per speaker.
    columns:
      speaker: {scheme_id: speaker}
  emotion.categories.desired.dev:
    type: filewise
    description: Emotion the actors were asked to present, dev split
    split_id: dev
    columns:
      emotion: {description: Desired emotion, scheme_id: emotion}
      emotion.intensity: {description: Desired intensity of emotion, scheme_id: emotion.intensity}
  emotion.categories.desired.test:
    type: filewise
    description: Emotion the actors were asked to present, test split Samples with
      audio issues were removed from this table.
    split_id: test
    columns:
      emotion: {description: Desired emotion, scheme_id: emotion}
      emotion.intensity: {description: Desired intensity of emotion, scheme_id: emotion.intensity}
  emotion.categories.desired.train:
    type: filewise
    description: Emotion the actors were asked to present, train split
    split_id: train
    columns:
      emotion: {description: Desired emotion, scheme_id: emotion}
      emotion.intensity: {description: Desired intensity of emotion, scheme_id: emotion.intensity}
  emotion.categories.dev:
    type: filewise
    description: The emotions that were chosen the most often for the voice modality,
      dev split.
    split_id: dev
    columns:
      emotion.0: {scheme_id: emotion}
      emotion.0.level: {scheme_id: emotion.level}
      emotion.1: {scheme_id: emotion}
      emotion.1.level: {scheme_id: emotion.level}
      emotion.2: {scheme_id: emotion}
      emotion.2.level: {scheme_id: emotion.level}
      emotion.3: {scheme_id: emotion}
      emotion.3.level: {scheme_id: emotion.level}
      emotion.4: {scheme_id: emotion}
      emotion.4.level: {scheme_id: emotion.level}
  emotion.categories.dev.gold_standard:
    type: filewise
    description: Gold standard for emotion for the voice modality, dev split.
    split_id: dev
    columns:
      emotion: {description: 'Emotion category that was voted for most often, or no_agreement
          if there was more than one winning category.', scheme_id: emotion}
      emotion.level: {description: 'Gold standard of the emotion level for the winning
          emotion, or None if there was more than one winning category.', scheme_id: emotion.level}
      emotion.agreement: {description: Rater agreement of the emotion for the winning
          emotion., scheme_id: emotion.agreement}
  emotion.categories.dev.votes:
    type: filewise
    description: Rater votes for the voice modality.
    split_id: dev
    columns:
      anger: {scheme_id: votes}
      disgust: {scheme_id: votes}
      fear: {scheme_id: votes}
      happiness: {scheme_id: votes}
      neutral: {scheme_id: votes}
      sadness: {scheme_id: votes}
  emotion.categories.face.dev:
    type: filewise
    description: The emotions that were chosen the most often for the face modality,
      dev split.
    split_id: dev
    columns:
      emotion.0: {scheme_id: emotion}
      emotion.0.level: {scheme_id: emotion.level}
      emotion.1: {scheme_id: emotion}
      emotion.1.level: {scheme_id: emotion.level}
      emotion.2: {scheme_id: emotion}
      emotion.2.level: {scheme_id: emotion.level}
      emotion.3: {scheme_id: emotion}
      emotion.3.level: {scheme_id: emotion.level}
      emotion.4: {scheme_id: emotion}
      emotion.4.level: {scheme_id: emotion.level}
  emotion.categories.face.dev.gold_standard:
    type: filewise
    description: Gold standard for emotion for the face modality, dev split.
    split_id: dev
    columns:
      emotion: {description: 'Emotion category that was voted for most often, or no_agreement
          if there was more than one winning category.', scheme_id: emotion}
      emotion.level: {description: 'Gold standard of the emotion level for the winning
          emotion, or None if there was more than one winning category.', scheme_id: emotion.level}
      emotion.agreement: {description: Rater agreement of the emotion for the winning
          emotion., scheme_id: emotion.agreement}
  emotion.categories.face.dev.votes:
    type: filewise
    description: Rater votes for the face modality.
    split_id: dev
    columns:
      anger: {scheme_id: votes}
      disgust: {scheme_id: votes}
      fear: {scheme_id: votes}
      happiness: {scheme_id: votes}
      neutral: {scheme_id: votes}
      sadness: {scheme_id: votes}
  emotion.categories.face.test:
    type: filewise
    description: The emotions that were chosen the most often for the face modality,
      test split. Samples with audio issues were removed from this table.
    split_id: test
    columns:
      emotion.0: {scheme_id: emotion}
      emotion.0.level: {scheme_id: emotion.level}
      emotion.1: {scheme_id: emotion}
      emotion.1.level: {scheme_id: emotion.level}
      emotion.2: {scheme_id: emotion}
      emotion.2.level: {scheme_id: emotion.level}
      emotion.3: {scheme_id: emotion}
      emotion.3.level: {scheme_id: emotion.level}
      emotion.4: {scheme_id: emotion}
      emotion.4.level: {scheme_id: emotion.level}
  emotion.categories.face.test.gold_standard:
    type: filewise
    description: Gold standard for emotion for the face modality, test split. Samples
      with audio issues were removed from this table.
    split_id: test
    columns:
      emotion: {description: 'Emotion category that was voted for most often, or no_agreement
          if there was more than one winning category.', scheme_id: emotion}
      emotion.level: {description: 'Gold standard of the emotion level for the winning
          emotion, or None if there was more than one winning category.', scheme_id: emotion.level}
      emotion.agreement: {description: Rater agreement of the emotion for the winning
          emotion., scheme_id: emotion.agreement}
  emotion.categories.face.test.votes:
    type: filewise
    description: Rater votes for the face modality. Samples with audio issues were
      removed from this table.
    split_id: test
    columns:
      anger: {scheme_id: votes}
      disgust: {scheme_id: votes}
      fear: {scheme_id: votes}
      happiness: {scheme_id: votes}
      neutral: {scheme_id: votes}
      sadness: {scheme_id: votes}
  emotion.categories.face.train:
    type: filewise
    description: The emotions that were chosen the most often for the face modality,
      train split.
    split_id: train
    columns:
      emotion.0: {scheme_id: emotion}
      emotion.0.level: {scheme_id: emotion.level}
      emotion.1: {scheme_id: emotion}
      emotion.1.level: {scheme_id: emotion.level}
      emotion.2: {scheme_id: emotion}
      emotion.2.level: {scheme_id: emotion.level}
      emotion.3: {scheme_id: emotion}
      emotion.3.level: {scheme_id: emotion.level}
      emotion.4: {scheme_id: emotion}
      emotion.4.level: {scheme_id: emotion.level}
  emotion.categories.face.train.gold_standard:
    type: filewise
    description: Gold standard for emotion for the face modality, train split.
    split_id: train
    columns:
      emotion: {description: 'Emotion category that was voted for most often, or no_agreement
          if there was more than one winning category.', scheme_id: emotion}
      emotion.level: {description: 'Gold standard of the emotion level for the winning
          emotion, or None if there was more than one winning category.', scheme_id: emotion.level}
      emotion.agreement: {description: Rater agreement of the emotion for the winning
          emotion., scheme_id: emotion.agreement}
  emotion.categories.face.train.votes:
    type: filewise
    description: Rater votes for the face modality.
    split_id: train
    columns:
      anger: {scheme_id: votes}
      disgust: {scheme_id: votes}
      fear: {scheme_id: votes}
      happiness: {scheme_id: votes}
      neutral: {scheme_id: votes}
      sadness: {scheme_id: votes}
  emotion.categories.multimodal.dev:
    type: filewise
    description: The emotions that were chosen the most often for the multimodal modality,
      dev split.
    split_id: dev
    columns:
      emotion.0: {scheme_id: emotion}
      emotion.0.level: {scheme_id: emotion.level}
      emotion.1: {scheme_id: emotion}
      emotion.1.level: {scheme_id: emotion.level}
      emotion.2: {scheme_id: emotion}
      emotion.2.level: {scheme_id: emotion.level}
      emotion.3: {scheme_id: emotion}
      emotion.3.level: {scheme_id: emotion.level}
  emotion.categories.multimodal.dev.gold_standard:
    type: filewise
    description: Gold standard for emotion for the multimodal modality, dev split.
    split_id: dev
    columns:
      emotion: {description: 'Emotion category that was voted for most often, or no_agreement
          if there was more than one winning category.', scheme_id: emotion}
      emotion.level: {description: 'Gold standard of the emotion level for the winning
          emotion, or None if there was more than one winning category.', scheme_id: emotion.level}
      emotion.agreement: {description: Rater agreement of the emotion for the winning
          emotion., scheme_id: emotion.agreement}
  emotion.categories.multimodal.dev.votes:
    type: filewise
    description: Rater votes for the multimodal modality.
    split_id: dev
    columns:
      anger: {scheme_id: votes}
      disgust: {scheme_id: votes}
      fear: {scheme_id: votes}
      happiness: {scheme_id: votes}
      neutral: {scheme_id: votes}
      sadness: {scheme_id: votes}
  emotion.categories.multimodal.test:
    type: filewise
    description: The emotions that were chosen the most often for the multimodal modality,
      test split. Samples with audio issues were removed from this table.
    split_id: test
    columns:
      emotion.0: {scheme_id: emotion}
      emotion.0.level: {scheme_id: emotion.level}
      emotion.1: {scheme_id: emotion}
      emotion.1.level: {scheme_id: emotion.level}
      emotion.2: {scheme_id: emotion}
      emotion.2.level: {scheme_id: emotion.level}
      emotion.3: {scheme_id: emotion}
      emotion.3.level: {scheme_id: emotion.level}
  emotion.categories.multimodal.test.gold_standard:
    type: filewise
    description: Gold standard for emotion for the multimodal modality, test split.
      Samples with audio issues were removed from this table.
    split_id: test
    columns:
      emotion: {description: 'Emotion category that was voted for most often, or no_agreement
          if there was more than one winning category.', scheme_id: emotion}
      emotion.level: {description: 'Gold standard of the emotion level for the winning
          emotion, or None if there was more than one winning category.', scheme_id: emotion.level}
      emotion.agreement: {description: Rater agreement of the emotion for the winning
          emotion., scheme_id: emotion.agreement}
  emotion.categories.multimodal.test.votes:
    type: filewise
    description: Rater votes for the multimodal modality. Samples with audio issues
      were removed from this table.
    split_id: test
    columns:
      anger: {scheme_id: votes}
      disgust: {scheme_id: votes}
      fear: {scheme_id: votes}
      happiness: {scheme_id: votes}
      neutral: {scheme_id: votes}
      sadness: {scheme_id: votes}
  emotion.categories.multimodal.train:
    type: filewise
    description: The emotions that were chosen the most often for the multimodal modality,
      train split.
    split_id: train
    columns:
      emotion.0: {scheme_id: emotion}
      emotion.0.level: {scheme_id: emotion.level}
      emotion.1: {scheme_id: emotion}
      emotion.1.level: {scheme_id: emotion.level}
      emotion.2: {scheme_id: emotion}
      emotion.2.level: {scheme_id: emotion.level}
      emotion.3: {scheme_id: emotion}
      emotion.3.level: {scheme_id: emotion.level}
  emotion.categories.multimodal.train.gold_standard:
    type: filewise
    description: Gold standard for emotion for the multimodal modality, train split.
    split_id: train
    columns:
      emotion: {description: 'Emotion category that was voted for most often, or no_agreement
          if there was more than one winning category.', scheme_id: emotion}
      emotion.level: {description: 'Gold standard of the emotion level for the winning
          emotion, or None if there was more than one winning category.', scheme_id: emotion.level}
      emotion.agreement: {description: Rater agreement of the emotion for the winning
          emotion., scheme_id: emotion.agreement}
  emotion.categories.multimodal.train.votes:
    type: filewise
    description: Rater votes for the multimodal modality.
    split_id: train
    columns:
      anger: {scheme_id: votes}
      disgust: {scheme_id: votes}
      fear: {scheme_id: votes}
      happiness: {scheme_id: votes}
      neutral: {scheme_id: votes}
      sadness: {scheme_id: votes}
  emotion.categories.test:
    type: filewise
    description: The emotions that were chosen the most often for the voice modality,
      test split. Samples with audio issues were removed from this table.
    split_id: test
    columns:
      emotion.0: {scheme_id: emotion}
      emotion.0.level: {scheme_id: emotion.level}
      emotion.1: {scheme_id: emotion}
      emotion.1.level: {scheme_id: emotion.level}
      emotion.2: {scheme_id: emotion}
      emotion.2.level: {scheme_id: emotion.level}
      emotion.3: {scheme_id: emotion}
      emotion.3.level: {scheme_id: emotion.level}
      emotion.4: {scheme_id: emotion}
      emotion.4.level: {scheme_id: emotion.level}
  emotion.categories.test.gold_standard:
    type: filewise
    description: Gold standard for emotion for the voice modality, test split. Samples
      with audio issues were removed from this table.
    split_id: test
    columns:
      emotion: {description: 'Emotion category that was voted for most often, or no_agreement
          if there was more than one winning category.', scheme_id: emotion}
      emotion.level: {description: 'Gold standard of the emotion level for the winning
          emotion, or None if there was more than one winning category.', scheme_id: emotion.level}
      emotion.agreement: {description: Rater agreement of the emotion for the winning
          emotion., scheme_id: emotion.agreement}
  emotion.categories.test.votes:
    type: filewise
    description: Rater votes for the voice modality. Samples with audio issues were
      removed from this table.
    split_id: test
    columns:
      anger: {scheme_id: votes}
      disgust: {scheme_id: votes}
      fear: {scheme_id: votes}
      happiness: {scheme_id: votes}
      neutral: {scheme_id: votes}
      sadness: {scheme_id: votes}
  emotion.categories.train:
    type: filewise
    description: The emotions that were chosen the most often for the voice modality,
      train split.
    split_id: train
    columns:
      emotion.0: {scheme_id: emotion}
      emotion.0.level: {scheme_id: emotion.level}
      emotion.1: {scheme_id: emotion}
      emotion.1.level: {scheme_id: emotion.level}
      emotion.2: {scheme_id: emotion}
      emotion.2.level: {scheme_id: emotion.level}
      emotion.3: {scheme_id: emotion}
      emotion.3.level: {scheme_id: emotion.level}
      emotion.4: {scheme_id: emotion}
      emotion.4.level: {scheme_id: emotion.level}
  emotion.categories.train.gold_standard:
    type: filewise
    description: Gold standard for emotion for the voice modality, train split.
    split_id: train
    columns:
      emotion: {description: 'Emotion category that was voted for most often, or no_agreement
          if there was more than one winning category.', scheme_id: emotion}
      emotion.level: {description: 'Gold standard of the emotion level for the winning
          emotion, or None if there was more than one winning category.', scheme_id: emotion.level}
      emotion.agreement: {description: Rater agreement of the emotion for the winning
          emotion., scheme_id: emotion.agreement}
  emotion.categories.train.votes:
    type: filewise
    description: Rater votes for the voice modality.
    split_id: train
    columns:
      anger: {scheme_id: votes}
      disgust: {scheme_id: votes}
      fear: {scheme_id: votes}
      happiness: {scheme_id: votes}
      neutral: {scheme_id: votes}
      sadness: {scheme_id: votes}
  files:
    type: filewise
    columns:
      speaker: {scheme_id: speaker}
      corrupted: {scheme_id: corrupted}
  sentence:
    type: filewise
    columns:
      sentence: {scheme_id: sentence}
audb:
  root: /Users/alfred/Documents/SER/crema-d/1.3.0/fe182b91
  version: 1.3.0
  flavor: {bit_depth: null, channels: null, format: wav, mixdown: true, sampling_rate: 16000}
  complete: true
pdf: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4313618/
